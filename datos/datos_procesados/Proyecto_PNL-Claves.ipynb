{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Proyecto, twitter<span class=\"tocSkip\"></span></h1> \n",
    "\n",
    ">**Maestría en Analítica de Datos**  \n",
    ">**Facultad de Ingeniería y Ciencias Básicas.**  \n",
    ">**Universidad Central  2021 - III**  \n",
    ">**Integrantes del trabajo:**  \n",
    "- Maria Alejandra Castillo Pabon\n",
    "- David Alejandro Ballesteros Díaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Librerias y Parametros de Conexión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\malej\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: regex in c:\\users\\malej\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\malej\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\malej\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\malej\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\malej\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9cfcffb4a75d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vader_lexicon'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# !pip install tweepy\n",
    "# !pip install selenium\n",
    "# !pip install pyvis\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from msedge.selenium_tools import Edge, EdgeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import tweepy\n",
    "import json\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "!pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "!pip install Goslate\n",
    "import goslate\n",
    "from pyvis.network import Network\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones personalizadas (16)\n",
    "## Selenium Bot (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activar Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlador ():\n",
    "    options = EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    driver = Edge(options=options)\n",
    "    return(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ir a una url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ir_pagina (driver,url):\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar sesion en twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iniciar_sesion(driver,url,user,my_password):\n",
    "    ir_pagina(driver,url)\n",
    "    username = driver.find_element_by_xpath('//input[@name=\"session[username_or_email]\"]')\n",
    "    username.send_keys(user)\n",
    "    password = driver.find_element_by_xpath('//input[@name=\"session[password]\"]')\n",
    "    password.send_keys(my_password)\n",
    "    password.send_keys(Keys.RETURN)\n",
    "    return('logueado')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ir a los tweet y respuestas de una persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagina_tweet (driver,nombre):\n",
    "    url='https://twitter.com/'+nombre+'/with_replies'\n",
    "    ir_pagina(driver,url)\n",
    "    driver.execute_script(\"document.body.style.zoom='50%'\")\n",
    "    return ('conectado a la página '+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_tweet(card):\n",
    "\n",
    "    username = card.find_element_by_xpath('.//span').text\n",
    "    try:\n",
    "        handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    \n",
    "    comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "    responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    text = comment + responding\n",
    "    reply_cnt = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    retweet_cnt = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    like_cnt = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "#    link= card.find_elements_by_css_selector('.css-4rbku5.css-18t94o4.css-901oao.r-9ilb82.r-1loqt21.r-1q142lx.r-1qd0xha.r-a023e6.r-16dba41.r-rjixqe.r-bcqeeo.r-3s2u2q.r-qvutc0')[0].get_attribute('href')  \n",
    "#    link= card.find_elements_by_css_selector('.css-4rbku5.css-18t94o4.css-901oao.r-9ilb82.r-1loqt21.r-1q142lx.r-37j5jr.r-a023e6.r-16dba41.r-rjixqe.r-bcqeeo.r-3s2u2q.r-qvutc0')[0].get_attribute('href')  \n",
    "    link= card.find_elements_by_css_selector('.css-4rbku5.css-18t94o4.css-901oao.r-14j79pv.r-1loqt21.r-1q142lx.r-37j5jr.r-a023e6.r-16dba41.r-rjixqe.r-bcqeeo.r-3s2u2q.r-qvutc0')[0].get_attribute('href')  \n",
    "    emoji_tags = card.find_elements_by_xpath('.//img[contains(@src, \"emoji\")]')\n",
    "    emoji_list = []\n",
    "    for tag in emoji_tags:\n",
    "        filename = tag.get_attribute('src')\n",
    "        try:\n",
    "            emoji = chr(int(re.search(r'svg\\/([a-z0-9]+)\\.svg', filename).group(1), base=16))\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        if emoji:\n",
    "            emoji_list.append(emoji)\n",
    "    emojis = ' '.join(emoji_list)\n",
    "    \n",
    "    tweet = (username, handle, postdate, text, emojis, reply_cnt, retweet_cnt, like_cnt,link)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de los Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_tweets (driver,fecha_fin = \"01-01-2001\"):\n",
    "    data = []\n",
    "    tweet_ids = set()\n",
    "    last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        page_cards = driver.find_elements_by_xpath('//articulo[@data-testid=\"tweet\"]')\n",
    "        for card in page_cards[-15:]:\n",
    "            tweet = obtener_tweet(card)\n",
    "            if tweet is None:\n",
    "                pass              \n",
    "            else:\n",
    "                if 1 ==1 :\n",
    "                    tweet_id = ''.join(tweet)\n",
    "                    if tweet_id not in tweet_ids:\n",
    "                        tweet_ids.add(tweet_id)\n",
    "                        data.append(tweet)\n",
    "                else:\n",
    "                    scrolling=False\n",
    "        scroll_attempt = 0\n",
    "        while True:\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            sleep(2)\n",
    "            curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "            if last_position == curr_position:\n",
    "                scroll_attempt += 1\n",
    "\n",
    "                if scroll_attempt >= 3:\n",
    "                    scrolling = False\n",
    "                    break\n",
    "                else:\n",
    "                    sleep(2) # attempt another scroll\n",
    "            else:\n",
    "                last_position = curr_position\n",
    "                break\n",
    "    print(\"fin extracción\")\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_tweets (nombre_archivo,lista):\n",
    "    with open(nombre_archivo, 'w', newline='', encoding=\"utf-8\") as f:\n",
    "        header = ['nombre', 'usuario', 'fecha', 'texto', 'emoticon', 'cantidad_comentarios', 'cantidad_likes', 'Cantidad_Retweets']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(lista)\n",
    "    return ('Se guardo el arhivo '+nombre_archivo+' con '+str(len(lista))+' registros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "usuario='@alejacp4'\n",
    "clave = getpass()\n",
    "url='https://www.twitter.com/login'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=controlador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conectado a la página https://twitter.com/MariaFdaCabal/with_replies'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## petrogustavo (david)\n",
    "## MariaFdaCabal  (david)\n",
    "## ingrodolfohdez (aleja)\n",
    "\n",
    "pagina_tweet(driver,'MariaFdaCabal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin extracción\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Se guardo el arhivo prueba.csv con 0 registros'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## from:sergio_fajardo since:2021-07-01 until:2021-08-29\n",
    "## from:sergio_fajardo since:2021-01-01 until:2021-07-01\n",
    "## from:ingrodolfohdez since:2021-01-01 until:2021-08-29\n",
    "tweets=inf_tweets(driver,\"01-06-2000\") \n",
    "guardar_tweets (\"prueba.csv\",tweets)\n",
    "#guardar_tweets (\"pruebapetrolink.csv\",tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagina_tweet(driver,'ingrodolfohdez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=inf_tweets(driver,\"01-06-2020\")\n",
    "guardar_tweets (\"ingrodolfohdez2708.csv\",tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweets= pd.read_csv('tweets_sergio.csv')\n",
    "df_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy (2)\n",
    "### Información General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_general(nombre):\n",
    "    columnas = ['fecha_reporte','id', 'nombre', 'usuario','descripcion','cantidad_seguidores','cantidad_sigue','fecha_creacion']\n",
    "    df_inf_general = pd.DataFrame(columns=columnas)\n",
    "    data = api.get_user(\"@\"+nombre)\n",
    "    id_fajardo=data._json [\"id\"]\n",
    "    sigue=data._json [\"friends_count\"]\n",
    "    df_inf_general=df_inf_general.append({'fecha_reporte':date.today(),\n",
    "                                         'id':id_fajardo,\n",
    "                                         'nombre':data._json [\"name\"],\n",
    "                                         'usuario':data._json [\"screen_name\"],\n",
    "                                         'descripcion':data._json [\"description\"],\n",
    "                                         'cantidad_seguidores':data._json [\"followers_count\"],\n",
    "                                         'cantidad_sigue':sigue,\n",
    "                                         'fecha_creacion':data._json [\"created_at\"]},ignore_index=True)\n",
    "    return(df_inf_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personas que sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigue_a(numero_id,cantidad):\n",
    "    columnas = ['id', 'nombre', 'usuario','descripcion','cantidad_seguidores','cantidad_sigue','fecha_creacion']\n",
    "    df_sigue = pd.DataFrame(columns=columnas)\n",
    "    for user in tweepy.Cursor(api.friends, id=numero_id).items(cantidad):\n",
    "        df_sigue=df_sigue.append({'id':user._json [\"id\"],\n",
    "                                  'nombre':user._json [\"name\"],\n",
    "                                  'usuario':user._json [\"screen_name\"],\n",
    "                                  'descripcion':user._json [\"description\"],\n",
    "                                  'cantidad_seguidores':user._json [\"followers_count\"],\n",
    "                                  'cantidad_sigue':user._json [\"friends_count\"],\n",
    "                                  'fecha_creacion':user._json [\"created_at\"]},ignore_index=True)\n",
    "    return(df_sigue)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar(texto):\n",
    "    nuevo_texto = texto\n",
    "    if nuevo_texto is None:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            nuevo_texto = texto.lower()\n",
    "        except:\n",
    "            pass\n",
    "        nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
    "        regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\-\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~\\\\¡\\\\¿]'\n",
    "        nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
    "        nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
    "        nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "        nuevo_texto=nuevo_texto.replace(\"replying to\", \"\")\n",
    "        nuevo_texto=nuevo_texto.replace(\"Replying to\", \"\")\n",
    "        nuevo_texto=nuevo_texto.replace(\"sergio fajardo\", \"\")\n",
    "    return(nuevo_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traducción Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traducir (texto):\n",
    "    gs = goslate.Goslate()\n",
    "    texto=gs.translate(texto, 'en')\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificacion (df):\n",
    "    condiciones = [(df['Sentimiento']< 0),\n",
    "                   (df['Sentimiento'] <= 0.4),\n",
    "                   (df['Sentimiento'] <= 1)]\n",
    "    rangos=np.array((\"Negativo\", \"Neutro\", \"Positivo\"), dtype=\"str\")\n",
    "    df[\"sentimiento1\"] = np.select(condiciones, rangos)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLuvia de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lluvia(df,texto):\n",
    "    stop_words = list(stopwords.words('spanish'))\n",
    "    stop_words.extend((\"sergio\", \"fajardo\", \"sergio fajardo\",\"hoy\",\"sergiofajardo\"))\n",
    "    df=df.dropna()\n",
    "    text = ' '.join(df) \n",
    "    wordcloud = WordCloud(width=1024, height=800, stopwords=stop_words, background_color=\"white\", min_font_size=14).generate(text) \n",
    "    plt.figure(figsize= (8, 8), facecolor=None)\n",
    "    plt.suptitle(texto,size=20) \n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off') \n",
    "    plt.tight_layout(pad = 0) \n",
    "    return (plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafro(df, usuario,cantidad,nombre,texto):\n",
    "    ids=[nombre for nombre in df[usuario]]\n",
    "    valor=[valor for valor in df[cantidad]]\n",
    "    bonds=[[0,x+1] for x in range (len (df))]\n",
    "    titulo=[valor for valor in df[nombre]]\n",
    "\n",
    "    g = Network(\"850px\", \"95%\",notebook=True,font_color='white',heading=texto)\n",
    "    for x in range(len(ids)+1):\n",
    "        if x == 0:\n",
    "            g.add_node(x,label='Sergio Fajardo',value='1587923',physics=True,size=30,title='Sergio Fajardo\\n->Seguidores: '+ format(1587923,',d'),color='#0044ff',)            \n",
    "        else:\n",
    "            if valor[x-1] > 1000000:\n",
    "                g.add_node(x,label=' ',value=valor[x-1],physics=True,size=30,title=titulo[x-1]+'\\n @'+ids[x-1]+'\\n->Seguidores: '+ format(valor[x-1],',d'),color='#ff0077')        \n",
    "\n",
    "            g.add_node(x,label=' ',value=valor[x-1],physics=True,size=30,title=titulo[x-1]+'\\n @'+ids[x-1]+'\\n->Seguidores: '+ format(valor[x-1],',d'))\n",
    "\n",
    "    g.add_edges(bonds)\n",
    "    return(g.show('comunidad.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie (df):\n",
    "    df=df[['sentimiento1','Sentimiento']].groupby(['sentimiento1'],as_index=False).count()\n",
    "    fig = go.Figure(data=[go.Pie(labels=df['sentimiento1'], values=df['Sentimiento'], hole=.6)])\n",
    "    return(fig.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parámetros\n",
    "## Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"SlwdATPasmyIhHrBUiQ0SyH6f\"\n",
    "consumer_secret = \"38DRuXjkv7lb7C2Ufqw5JupKjUfMh5U0HS7HoSRfjxnhCMy9eJ\"\n",
    "access_token = \"294848614-Sf5ulXpdIfrMrabSgkDJAvXbN3GhWN0TTDlT3JJU\"\n",
    "access_token_secret = \"EntjBRbv9QGetACHmP5iWDv5qQTBpDJIDvSBchvXMIaiU\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth,\n",
    "                 wait_on_rate_limit=True,\n",
    "                 wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrar Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Información Sergio Fajardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inf_general('sergio_fajardo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las personas que sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigue_a(25185308,415).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sigue.to_csv('seguidor.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitters publicados por Sergio Fajardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de scraping de twitter\n",
    "![selinium](https://raw.githubusercontent.com/Daviddalejandro/Visualizacion/2eeaa18da1fcdf7a44c0d549fcb19f94e34c5182/imagenes/Selinium.gif \"selinium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets mas comentados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[link for link in df_tweets.sort_values('cantidad_comentarios',ascending=False).head(3).link]\n",
    "texto=[texto for texto in df_tweets.sort_values('cantidad_comentarios',ascending=False).head(3).texto]\n",
    "for x in range(len(links)):\n",
    "    print('Link '+str([x+1])+' '+links[x],'\\n')\n",
    "    print(texto[x],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Información de tweets mas comentados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=controlador()\n",
    "ir_pagina(driver,links[0])\n",
    "tweets=inf_tweets(driver)\n",
    "guardar_tweets (\"link1.csv\",tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver=controlador()\n",
    "ir_pagina(driver,links[1])\n",
    "tweets=inf_tweets(driver)\n",
    "guardar_tweets (\"link2.csv\",tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver=controlador()\n",
    "ir_pagina(driver,links[2])\n",
    "tweets=inf_tweets(driver)\n",
    "guardar_tweets (\"link3.csv\",tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tendencia política de Sergio Fajardo en twitter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets= pd.read_csv('tweets_sergio.csv')\n",
    "df_tweets = df_tweets.where(pd.notnull(df_tweets), None)\n",
    "df_link1=pd.read_csv('df_link1.csv')\n",
    "df_link1 = df_link1.where(pd.notnull(df_link1), None)\n",
    "df_link2=pd.read_csv('df_link2.csv')\n",
    "df_link2 = df_link2.where(pd.notnull(df_link2), None)\n",
    "df_link3=pd.read_csv('df_link3.csv')                   \n",
    "df_link3 = df_link3.where(pd.notnull(df_link3), None)\n",
    "df_sigue= pd.read_csv('df_sigue.csv')\n",
    "df_sigue = df_sigue.where(pd.notnull(df_sigue), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid= SentimentIntensityAnalyzer()\n",
    "df_tweets['texto_tokenizado'] = df_tweets['texto'].apply(limpiar)\n",
    "\n",
    "df_link1['texto_tokenizado'] = df_link1['texto'].apply(limpiar)\n",
    "#df_link1['traduccion']=df_link1['texto_tokenizado'].apply(traducir)\n",
    "df_link1['Sentimiento']=df_link1['traduccion'].apply(lambda i: sid.polarity_scores(str(i))['compound'])\n",
    "df_link1=clasificacion(df_link1)\n",
    "\n",
    "#df_link2['texto_tokenizado'] = df_link2['texto'].apply(limpiar)\n",
    "#df_link2['traduccion']=df_link2['texto_tokenizado'].apply(traducir)\n",
    "df_link2['Sentimiento']=df_link2['traduccion'].apply(lambda i: sid.polarity_scores(str(i))['compound'])\n",
    "df_link2=clasificacion(df_link2)\n",
    "\n",
    "#df_link3['texto_tokenizado'] = df_link3['texto'].apply(limpiar)\n",
    "#df_link3['traduccion']=df_link3['texto_tokenizado'].apply(traducir)\n",
    "df_link3['Sentimiento']=df_link3['traduccion'].apply(lambda i: sid.polarity_scores(str(i))['compound'])\n",
    "df_link3=clasificacion(df_link3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lluvia(df_tweets['texto_tokenizado'],\"Palabras más usuadas por Fajardo en sus tweets\")\n",
    "grafro(df_sigue, 'usuario','cantidad_seguidores','nombre','A quién sigue Sergio Fajardo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto[0])\n",
    "lluvia(df_link1['texto_tokenizado'],'')\n",
    "pie(df_link1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto[1])\n",
    "lluvia(df_link2['texto_tokenizado'],'')\n",
    "pie(df_link2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto[2])\n",
    "lluvia(df_link3['texto_tokenizado'],'')\n",
    "pie(df_link3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
