{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Proyecto, Procesamiento de lenguaje natural aplicado al análisis de opinión política para las elecciones presidenciales en Colombia 2022<span class=\"tocSkip\"></span></h1> \n",
    "\n",
    ">**Maestría en Analítica de Datos**  \n",
    ">**Facultad de Ingeniería y Ciencias Básicas.**  \n",
    ">**Universidad Central  2021 - III**  \n",
    ">**Integrantes del trabajo:**  \n",
    ">- Maria Alejandra Castillo Pabon\n",
    ">- David Alejandro Ballesteros Díaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias\n",
    "Las librerias principales a instalar para el proceso de extracción son:\n",
    "* **tweepy**: API proporcianada por Tweeter para extraer información de la red social, pero con restricciones de cantidad al ser gratuita.\n",
    "* **selenium**: Bot para extracción de información de paginas HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "#!pip install selenium\n",
    "#!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from msedge.selenium_tools import Edge, EdgeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import tweepy\n",
    "import json\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones personalizadas\n",
    "A continuación se describen las funciones personalizadas para extracción de la información, dividas en tres grandes grupos:\n",
    "* **Selenium BOT**: Funciones encaminadas para activación del BOT y extracción de la información de tweets publicados por los usuarios de Tweeter.\n",
    "* **Tweepy**: Funciones encaminadas para la extracción de la información por usuario del perfil general y las usuarios que sigue.\n",
    "* **complementos**: Funciones para guardar la información en formato CSV y modificar texto en campos numéricos.\n",
    "\n",
    "## Selenium Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activar Bot\n",
    "Función para abrir la ventana de EDGE en modo automático.  \n",
    "Nota: El Bot esta configurado en navegador ya que presenta un mayor rendimiento, al momento de extracción de la información de una página HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlador ():\n",
    "    options = EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    driver = Edge(options=options)\n",
    "    return(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ir a una url\n",
    "Función para excribir automaticamente dentro de la barra de direcciones la URL que se indique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ir_pagina (driver,url):\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets por usuario\n",
    "Función para crear la URL e ir a la pagina HTML donde se encuentre la información de los tweets de un usuario por rango de fechas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagina_tweet (driver,usuario,fecha_inicio=0,fecha_fin=0):\n",
    "    if fecha_inicio==0 and fecha_fin==0:\n",
    "        url='https://twitter.com/'+usuario+'/with_replies'\n",
    "    else:\n",
    "        url='https://twitter.com/search?q=%23from%3A'+usuario+'%20since%3A'+fecha_inicio+'%20until%3A'+fecha_fin+'&src=typed_query&f=live'\n",
    "    ir_pagina(driver,url)\n",
    "    driver.execute_script(\"document.body.style.zoom='80%'\")\n",
    "    return ('conectado a la página '+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener tweet\n",
    "Función para extraer por cada carta o grupo de sección de un HTML la información del tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_tweet(card):\n",
    "    try:\n",
    "        username = (card.find_element_by_xpath('.//div[2]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]').text).split('\\n', 1)[0]\n",
    "    except:\n",
    "        username=\"\"\n",
    "    try:\n",
    "        handle = (card.find_element_by_xpath('.//div[2]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]').text).split('\\n', 1)[0]\n",
    "    except:\n",
    "        handle=\"\"\n",
    "    try:\n",
    "        postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except:\n",
    "        postdate=\"\"\n",
    "    try:\n",
    "        text = card.find_element_by_xpath('.//div[2]/div[2]/div[2]/div[2]/div[1]').text\n",
    "    except:\n",
    "        text=1\n",
    "    if text == 1:\n",
    "        try:\n",
    "            text = card.find_element_by_xpath('.//div[2]/div[2]/div[2]/div[1]').text\n",
    "        except:\n",
    "            text=\"\"\n",
    "    try:\n",
    "        reply_cnt = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    except:\n",
    "        reply_cnt=\"\"\n",
    "    try:\n",
    "        retweet_cnt = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    except:\n",
    "        retweet_cnt=\"\"\n",
    "    try:\n",
    "        like_cnt = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text \n",
    "    except:\n",
    "        like_cnt=\"\"\n",
    "    try:\n",
    "        #link= card.find_elements_by_css_selector('.css-4rbku5.css-18t94o4.css-901oao.r-14j79pv.r-1loqt21.r-1q142lx.r-37j5jr.r-a023e6.r-16dba41.r-rjixqe.r-bcqeeo.r-3s2u2q.r-qvutc0')[0].get_attribute('href')#Male\n",
    "        link= card.find_elements_by_css_selector('.css-4rbku5.css-18t94o4.css-901oao.r-9ilb82.r-1loqt21.r-1q142lx.r-37j5jr.r-a023e6.r-16dba41.r-rjixqe.r-bcqeeo.r-3s2u2q.r-qvutc0')[0].get_attribute('href')#David  \n",
    "    except:\n",
    "        link=\"\"\n",
    "    try:\n",
    "        emoji_tags = card.find_elements_by_xpath('.//img[contains(@src, \"emoji\")]')\n",
    "        emoji_list = []\n",
    "        for tag in emoji_tags:\n",
    "            filename = tag.get_attribute('src')\n",
    "            try:\n",
    "                emoji = chr(int(re.search(r'svg\\/([a-z0-9]+)\\.svg', filename).group(1), base=16))\n",
    "            except :\n",
    "                continue\n",
    "            if emoji:\n",
    "                emoji_list.append(emoji)\n",
    "        emojis = ' '.join(emoji_list)\n",
    "    except:\n",
    "        emojis=''\n",
    "    tweet = (username, handle, postdate, text, emojis, reply_cnt, retweet_cnt, like_cnt,link)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción Tweets\n",
    "Función que toma cada elementos de la pagina HTML que contienen varios tweets, y a través de la función \"obtener tweets\", crea una lista con la información correspondiente de cada tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_tweets (driver,fecha_fin = \"01-01-2001\"):\n",
    "    data = []\n",
    "    tweet_ids = set()\n",
    "    last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        page_cards = driver.find_elements_by_xpath('//article[@data-testid=\"tweet\"]')\n",
    "        for card in page_cards[-15:]:\n",
    "            tweet = obtener_tweet(card)\n",
    "            if tweet is None:\n",
    "                pass              \n",
    "            else:\n",
    "                if datetime.strptime(\"01-01-2020\",'%d-%m-%Y')>datetime.strptime(fecha_fin,'%d-%m-%Y'):\n",
    "                    tweet_id = ''.join(tweet)\n",
    "                    if tweet_id not in tweet_ids:\n",
    "                        tweet_ids.add(tweet_id)\n",
    "                        data.append(tweet)                    \n",
    "                else:\n",
    "                    scrolling=False\n",
    "        scroll_attempt = 0\n",
    "        while True:\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            sleep(2)\n",
    "            curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "            if last_position == curr_position:\n",
    "                scroll_attempt += 1\n",
    "\n",
    "                if scroll_attempt >= 3:\n",
    "                    scrolling = False\n",
    "                    break\n",
    "                else:\n",
    "                    sleep(2)\n",
    "            else:\n",
    "                last_position = curr_position\n",
    "                break\n",
    "    print(\"fin extracción\")\n",
    "    return (data,datetime.strptime((tweet[2][0:10]), '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar Tweets\n",
    "Función para guardar en CSV los tweets contenidos en la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_tweets (nombre_archivo,lista):\n",
    "    with open(nombre_archivo, 'w', newline='', encoding=\"utf-8\") as f:\n",
    "        header = ['nombre', 'usuario', 'fecha', 'texto', 'emoticon', 'cantidad_comentarios', 'cantidad_likes', 'Cantidad_Retweets','link']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(lista)\n",
    "    return ('Se guardo el arhivo '+nombre_archivo+' con '+str(len(lista))+' registros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy\n",
    "### Parámetros\n",
    "Función para acceder, autenticarse y activar la API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = os.getenv(\"consumer_key\")\n",
    "consumer_secret = os.getenv(\"consumer_secret\")\n",
    "access_token = os.getenv(\"access_token\")\n",
    "access_token_secret = os.getenv(\"access_token_secret\")\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth,\n",
    "                 wait_on_rate_limit=True,\n",
    "                 wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfil del usuario\n",
    "Función para extracción de la información general del usuario de Tweeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfil_usuario(nombre):\n",
    "    columnas = ['fecha_reporte','id', 'nombre', 'usuario','descripcion','cantidad_seguidores','cantidad_sigue','fecha_creacion']\n",
    "    df_inf_general = pd.DataFrame(columns=columnas)\n",
    "    data = api.get_user(\"@\"+nombre)\n",
    "    id_usuario=data._json [\"id\"]\n",
    "    sigue=data._json [\"friends_count\"]\n",
    "    df_inf_general=df_inf_general.append({'fecha_reporte':date.today(),\n",
    "                                         'id':id_usuario,\n",
    "                                         'nombre':data._json [\"name\"],\n",
    "                                         'usuario':data._json [\"screen_name\"],\n",
    "                                         'descripcion':data._json [\"description\"],\n",
    "                                         'cantidad_seguidores':data._json [\"followers_count\"],\n",
    "                                         'cantidad_sigue':sigue,\n",
    "                                         'fecha_creacion':data._json [\"created_at\"]},ignore_index=True)\n",
    "    return(df_inf_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usuarios que sigue un usuario\n",
    "Función para extraer la información de los usuarios que sigue otro usuario de tweeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigue_a(numero_id,cantidad):\n",
    "    columnas = ['id', 'nombre', 'usuario','descripcion','cantidad_seguidores','cantidad_sigue','fecha_creacion']\n",
    "    df_sigue = pd.DataFrame(columns=columnas)\n",
    "    for user in tweepy.Cursor(api.friends, id=numero_id).items(cantidad):\n",
    "        df_sigue=df_sigue.append({'id':user._json [\"id\"],\n",
    "                                  'nombre':user._json [\"name\"],\n",
    "                                  'usuario':user._json [\"screen_name\"],\n",
    "                                  'descripcion':user._json [\"description\"],\n",
    "                                  'cantidad_seguidores':user._json [\"followers_count\"],\n",
    "                                  'cantidad_sigue':user._json [\"friends_count\"],\n",
    "                                  'fecha_creacion':user._json [\"created_at\"]},ignore_index=True)\n",
    "    return(df_sigue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar Dataframe - CSV\n",
    "Función para guardar los datos de un DataFrame en formato CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_csv (df,nombre_archivo):\n",
    "    df.to_csv(nombre_archivo+'.csv', index=False,encoding='utf-8')\n",
    "    return('El archivo '+nombre_archivo+'.csv fue guardado exitosamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto de miles\n",
    "Función para cambiar el valor de miles (español o ingles) a número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valor_k(x):\n",
    "    x=str(x)\n",
    "    if x.find(\".\")>0 or x.find(\",\")>0:\n",
    "        x=int(re.sub('[.,k,K,\\s,a-zA-Z]','',x))*100\n",
    "    elif x =='nan':\n",
    "        x=0\n",
    "    elif x.find(\"K\") >0 or x.find(\"mil\") >0:\n",
    "        x=int(re.sub('[k,K\\s,a-zA-Z]','',x))*1000\n",
    "    else:\n",
    "        x= int(x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de usarios\n",
    "Se crea una lista con los usuarios de tweeter de los precandidatos políticos a extraer la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios=(\"OIZuluaga\",\"MariaFdaCabal\",\"ingrodolfohdez\",\"petrogustavo\",\"sergio_fajardo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodos de Extracción\n",
    "Se crea un diccionario con los rangos requeridos para extraer los tweets de los usuarios.  \n",
    "Nota: se requieren estos rangos debido a la limitante de memoria que puede tener una pagina html al cargar demasiada información de tweets en esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodos={\n",
    "    'rango1': ['2021-08-28','2021-08-29'],\n",
    "    'rango2': ['2021-08-24','2021-08-27']\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfil de los usuarios en Twitter\n",
    "Se itera por cada uno de los usuarios para extraer y guardar su perfil en formato CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El archivo Inf_General_Candidatos_Twitter.csv fue guardado exitosamente'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "for usuario in usuarios:\n",
    "    df0=perfil_usuario(usuario)\n",
    "    df=pd.concat([df0, df])\n",
    "guardar_csv(df,\"Inf_General_Candidatos_Twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usuarios a los que se siguen en Twitter\n",
    "Se itera por cada uno de los usuarios para extaer y guardar los usuarios que ellos siguen a través de twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo sergio_fajardo_entorno.csv fue guardado exitosamente\n",
      "El archivo petrogustavo_entorno.csv fue guardado exitosamente\n",
      "El archivo ingrodolfohdez_entorno.csv fue guardado exitosamente\n",
      "El archivo MariaFdaCabal_entorno.csv fue guardado exitosamente\n",
      "El archivo OIZuluaga_entorno.csv fue guardado exitosamente\n"
     ]
    }
   ],
   "source": [
    "for id_usuario in df.id[0]:\n",
    "    df_1 = df[df['id'] == id_usuario]\n",
    "    usuario=df_1.usuario[0]\n",
    "    cantidad_sigue=df_1.cantidad_sigue[0]\n",
    "    nombre_archivo = usuario+\"_entorno\"\n",
    "    df=sigue_a(id_usuario,cantidad_sigue)\n",
    "    print(guardar_csv(df,nombre_archivo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets de cada precandidato\n",
    "Se realiza la activación del bot y se itera por cada usuario y periodo, para ir a la página de sus tweets y extraer y guaradar cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n"
     ]
    }
   ],
   "source": [
    "driver=controlador()\n",
    "sleep(5)\n",
    "for rango in periodos:\n",
    "    fecha_inicio = periodos[rango][0]\n",
    "    fecha_fin = periodos[rango][1]\n",
    "    for usuario in usuarios:\n",
    "        pagina_tweet(driver,usuario,fecha_inicio,fecha_fin)\n",
    "        tweets=inf_tweets(driver)\n",
    "        nombre_archivo=[usuario+\"_\"+fecha_inicio+\"_\"+fecha_fin+'.csv']\n",
    "        guardar_tweets (nombre_archivo[0],tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 links mas comentados de cada precandidato\n",
    "Se crea un proceso para extracción de las respuestas sobre los tweets mas comentados (top 5) por cada usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de los links\n",
    "Se itera por cada usuario para identificar los 5 tweets que mas comentarios generaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='C:\\\\Users\\David\\Python\\PNL\\Tweets'\n",
    "for usuario in usuarios:\n",
    "    df=pd.DataFrame()\n",
    "    try: \n",
    "        lista=[file_name for file_name in glob.glob(ruta+'/'+'*.csv') if file_name.find(usuario) > 0 ]\n",
    "        for archivo in lista:\n",
    "            df0= pd.read_csv(archivo,index_col=False)\n",
    "            df=pd.concat([df0, df])    \n",
    "        df['cantidad_comentarios']=df['cantidad_comentarios'].apply(valor_k)     \n",
    "        links=[link for link in df.sort_values('cantidad_comentarios',ascending=False).head(5).link]\n",
    "        locals()[\"links_\"+usuario] = links              \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://twitter.com/sergio_fajardo/status/1297702268020625408', 'https://twitter.com/sergio_fajardo/status/1283217336816865280', 'https://twitter.com/sergio_fajardo/status/1333797916486483968', 'https://twitter.com/sergio_fajardo/status/1285768190656688129', 'https://twitter.com/sergio_fajardo/status/1402682869131223049'] \n",
      "\n",
      "['https://twitter.com/mluciaramirez/status/1271226549426143233', 'https://twitter.com/AlvaroUribeVel/status/1314942928998084610', 'https://twitter.com/jeronimoauribem/status/1292167893153652739', 'https://twitter.com/IvanDuque/status/1390733669564887043', 'https://twitter.com/OIZuluaga/status/1426974730649747460'] \n",
      "\n",
      "['https://twitter.com/MariaFdaCabal/status/1397007956022022146', 'https://twitter.com/MariaFdaCabal/status/1398330107975061507', 'https://twitter.com/MariaFdaCabal/status/1346614913406558208', 'https://twitter.com/MariaFdaCabal/status/1379837106755936258', 'https://twitter.com/MariaFdaCabal/status/1395365369125261313'] \n",
      "\n",
      "['https://twitter.com/ingrodolfohdez/status/1427640203422978064', 'https://twitter.com/ingrodolfohdez/status/1358451879253061637', 'https://twitter.com/ingrodolfohdez/status/1429846789470003200', 'https://twitter.com/ingrodolfohdez/status/1410295313429151747', 'https://twitter.com/ingrodolfohdez/status/1431449318553174017'] \n",
      "\n",
      "['https://twitter.com/petrogustavo/status/1338105889702752261', 'https://twitter.com/petrogustavo/status/1278776880292925441', 'https://twitter.com/petrogustavo/status/1390151225094594560', 'https://twitter.com/petrogustavo/status/1357807391266471937', 'https://twitter.com/petrogustavo/status/1374434742884438017'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(links_sergio_fajardo,'\\n')\n",
    "print(links_OIZuluaga,'\\n')\n",
    "print(links_MariaFdaCabal,'\\n')\n",
    "print(links_ingrodolfohdez,'\\n')\n",
    "print(links_petrogustavo,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción\n",
    "A través de cada uno de los links mas comentados se ingresa a estos y se extrae su información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n",
      "fin extracción\n"
     ]
    }
   ],
   "source": [
    "usuarios=(\"OIZuluaga\",\"MariaFdaCabal\",\"ingrodolfohdez\",\"petrogustavo\",\"sergio_fajardo\")\n",
    "driver=controlador()\n",
    "sleep(5)\n",
    "for usuario in usuarios:\n",
    "    links=locals()[\"links_\"+usuario]\n",
    "    i=0\n",
    "    for link in links:\n",
    "        i=i+1\n",
    "        driver.get(link)\n",
    "        driver.execute_script(\"document.body.style.zoom='50%'\")\n",
    "        tweets=inf_tweets(driver)\n",
    "        guardar_tweets (usuario+\"_link\"+str(i)+\".csv\",tweets[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
